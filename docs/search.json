[
  {
    "objectID": "searchable_web_table.html",
    "href": "searchable_web_table.html",
    "title": "Making a searchable database table",
    "section": "",
    "text": "#### MAKING A SEARCHABLE TABLE FOR THE WEB ####\n\n# First -- let's talk about: what is the Internet? What IS a web page?\n# An oldie but a goodie from 2009: https://www.youtube.com/watch?v=7_LPdttKXPc\n# Bottom line, it's just a bunch of computers connected to each other. \n# A website? It's just files on someone else's computer (aka server)\n\n\n#We can use the \"DT\" package to easily make a sortable, filterable, searchable data table\n#Just this little bit of code does a whole lot - check it out:\n\nDT::datatable(events)\n\n\n\n\n\n\n\n#We can already sort, but what if we want to allow the table to be FILTERED too?\n#It's easy, we just add:\nDT::datatable(events, \n              rownames = FALSE, \n              filter = \"top\"# <--- NEW STUFF HERE\n              )\n\n\n\n\n\n\n\n#Now hmm, what's up with the filters on the text columns? Why aren't they working?\n#It's because of a quirk in DT tables where filters will only work on text that is converted to a factor\n#So let's do that\nevents <- events %>% \n  mutate(\n    state = as_factor(state),\n    event_type = as.factor(event_type)\n  )\n\n\n#Now let's try the DT table code again and see if it worked\nDT::datatable(events, \n              rownames = FALSE, \n              filter = \"top\")\n\n\n\n\n\n\n\n#Now, for the coup de gr?ce\n#let's add some buttons at the top of the page to let people copy, download, etc\n#we do that using a DT \"extenstion\" called, you guessed it, Buttons\n# https://rstudio.github.io/DT/extensions.html\n\nDT::datatable(events, \n              rownames = FALSE, \n              filter = \"top\", \n              extensions = 'Buttons', \n              options = list(   # <--- NEW STUFF STARTS HERE\n                dom = 'Bfrtip',\n                buttons = c('copy', 'csv', \"excel\")\n              )) %>%\n  DT::formatStyle('cand_lastname',  color = 'red', fontWeight = 'bold')\n\n\n\n\n\n\n\n## saving the result\n\n# first we just need to assign our table to a variable...\n\nmytable <- DT::datatable(events, \n                         rownames = FALSE, \n                         filter = \"top\", \n                         extensions = 'Buttons', \n                         options = list(\n                           dom = 'Bfrtip',\n                           buttons = c('copy', 'csv', \"excel\")\n                         )) %>%\n  DT::formatStyle('cand_lastname',  color = 'red', fontWeight = 'bold') \n\n# ... then just run this simple bit of code to export to html\nDT::saveWidget(mytable, \"mytable.html\")\n\n\n# We've now created a working web page that can be put anywhere on the internet we choose\n# Yay!\n\n# If we stay within the world of quarto though we don't need to export it, we can just display it\n# within the quarto page of course\n\nWhat if we have a little table and want a super minimal table with everything stripped out\n\nevents %>% \n  select(date, cand_lastname, city) %>% \n  head(5) %>% \n  DT::datatable(rownames = FALSE, \n                options = list(searching = FALSE, paging = FALSE, dom = \"tip\"))"
  },
  {
    "objectID": "academicpaper.html",
    "href": "academicpaper.html",
    "title": "Academic Paper",
    "section": "",
    "text": "Last fall I took the class Business Ethics with Professor Vikram Bhargava for my business major. In the class I was assigned to write about a moral dilemma that had business applications and challenge myself to logically argue my position on the matter utilizing scholarly articles.\nI chose to write about whether it was morally permissible for pharmaceutical companies to produce human euthanasia drugs. Based on my own synthesis and findings within scholarly articles I decided it was not morally permissible. The essay outlines my though process through a simple syllogism and expands on the objections or loopholes to my own argument. I attempted to fairly address each counterargument as I walk through my own argument.\n\nEthical Permissibility of the Production of Euthanasia Drugs\nINTRODUCTION:\nThere is much controversial debate surrounding whether or not human euthanasia is morally permissible. Inducing a person’s death no matter how much pain they are in is a moral dilemma, even if there is an arms length of distance between the agent and the act does not necessarily relieve the ethics/guilt of doing so. This is one reason why euthanasia pills look so appealing for those who are terminally ill. They can take it themselves, can choose to do so themselves without needing an external agent to do so for them etc. In order to establish a stronger, more convincing argument, we are going to grant that euthanasia in itself is ethically permissible, as the following syllogsim indicates.\nNo one should have to suffer excruciating pain if there is a better alternative\nIf there is a better alternative, it should be inflicted on the person\nDeath relieves excruciating pain\nDeath is a better alternative\nTherefore, death should be inflicted on the person. [1,2,4]\nNow, however, we will move onto the focus of the paper: whether it is ethically permissible for businesses to produce euthanasia drugs. In prelimary research of specific euthanasia drugs it was found that Seconal is the most common form of euthanasia drug. For many, if taken correctly, Seconal is just a strong sleeping pill. For the purpose of this paper Seconal will only be a death inducing drug. For pharmaceutical companies who wish to produce such drugs, there is significant backlash. Many companies have had to change their names (Court 1). Additionally, many have taken part in price gouging recipients of the deadly drug (Dembosky 1). In Georgia there is even such a thing as the Lethal Injection Secrecy Act which protects the identities of companies who “manufacture, prescribe or supply drugs used in executions” (Vivian 1). Based on the way businesses have behaved about the drug as well as the surrounding public, it is a relevant question to ask whether or not it is ethically permissible for companies to produce the drugs in the first place. I will argue that even if euthanasia in itself is morally permissible, it is not morally permissible for businesses to produce euthanasia drugs. I will demonstrate this argument by use of the Doctrine of Double Effect, commodification limits and criteria for blameworthiness in the patient’s death.\n\nTHE DOCTRINE OF DOUBLE EFFECT\n\nThe Doctrine of Double Effect stipulates that there is a “distinction between causing a morally grave harm as a side effect of pursuing a good end and causing a morally grave harm as a means of pursuing a good end” (McIntyre 1).\nThe best and most relevant example given to explain the Doctrine of Double Effect in regard to this paper is: “A doctor who intends to hasten the death of a terminally ill patient by injecting a large dose of morphine would act impermissibly because he intends to bring about the patient’s death. However, a doctor who intended to relieve the patient’s pain with that same dose and merely foresaw the hastening of the patient’s death would act permissibly (McIntyre 1).” The same action can be perceived in two different ways. One of which is impermissible and the other where it is permissible.\nThe New Catholic Encyclopedia provides four conditions for the application of the principle of double effect: The act itself must be morally good or at least indifferent. The agent may not positively will the bad effect but may permit it. If he could attain the good effect without the bad effect he should do so. The bad effect is sometimes said to be indirectly voluntary. The good effect must flow from the action at least as immediately (in the order of causality, though not necessarily in the order of time) as the bad effect. In other words the good effect must be produced directly by the action, not by the bad effect. Otherwise the agent would be using a bad means to a good end, which is never allowed. The good effect must be sufficiently desirable to compensate for the allowing of the bad effect (McIntyre 1).\nLet’s narrow it even further, let’s grant that under the Doctrine of Double Effect, pharmaceutical companies are ethically permitted to sell a drug with potentially fatal side effects (Masek 490-491). Regardless of Masek’s claim there are distinctions between the two. The biggest one being that with euthanasia drugs, death is not a likely side effect, it is a guaranteed end. Let’s apply the Doctrine of Double Effect to businesses who produce euthanasia drugs:\nFirst Criterion: Is the act itself immoral?\nFor businesses to create deadly drugs in itself is immoral. The production of the drug assumes use of the drug which then assumes death by the drug. By even creating it, it is willing death into being an opportunity/option to someone. Now let’s grant that it is not immoral to produce a deadly drug if no one uses it. While this may be true, it is unrealistic and also pointless. Why would you create a drug, put time and money into production, distribution, patents and all of the other assumed costs if no one were to use it? Realistically, the company would not. So we assume that someone is going to use the drug (meaning induce death) and that would not be able to happen if the business had not created that drug to use in the first place.\nSecond Criterion: Are we actually willing the bad effect to occur?\nThe business does not will people to die, they cannot will people to take their drug and they cannot will sickness upon people. For this reason, the second criterion does not support my argument. For the Doctrine to be accepted as morally permissible, all four criteria would have to refute my argument, not just one. Therefore, by already establishing that criteria one supports my argument has already made it impossible for the second to ruin it. I do however acknowledge this and will focus on 3-5 .\n2a: Can we obtain the good effects without the bad effects? If we can we should. Here is an important distinction: if we were talking about euthanasia in itself, the sick person is not able to get the good effect: diminished pain, without the bad effect: death. However, we instead describe a business. For a business, the good effect of producing the drug would be profits, happy shareholders, increased prestige, bigger salaries etc. The bad effect is the death of other people. Here, we can absolutely obtain the good effects without the bad effects. Pharmaceutical companies almost never produce one drug or if they do, pivoting to produce different drugs is extremely easy with their business model. Their company would be able to continue to make profits even if they did not produce Seconal.\nThird Criterion: Do the bad effects result as directly from the acts as the good effects?\nThe business’s good effect (profit) does stem directly from the bad effects. The profit will come when doctors buy the drugs but they will only have sustained profits if the doctors continue having demand. The demand therefore generates profits and increases in deaths are what increase demand. This means the company is using bad means to a good end, which is prohibited under the Doctrine.\nFourth Criterion: Are the good effects insufficient to offset the bad effects?\nI think that it would be logical to assume that the good effects of “profit” for a company do not offset the bad effects of life being lost. Additionally, I would argue it is actually wrong to take profit for a means to end life in general which will be discussed in the next section of the paper. From the Doctrine of Double Effect we can conclude that it is not morally permissible for a company to sell euthanasia drugs.\n2. MARKET LIMITS\nBefore we make the argument for market limits, we must first establish that a company is in fact the agent of death. Just because a company has an arms length distance from administering Seconal, does not mean they are ethically exempt from the consequences. If the business had not created the drug, it would never have been an option for doctors to utilize on patients or patients to use on themselves. This places culpability onto the business who engineered and sold it.\nNow one may argue that even if the business did not create the drug, then the ill patient would have found another means to their end. This is true, however it is ethically permissible because there would no longer be an arms length of distance to an external agent. The agent (the patient) would have created or found a solution on their own and would have administered it themselves. This does in fact pass by the standards of the Doctrine of Double Effect as morally sufficient. The problem comes in when a business is the one promoting and selling the euthanasia drug.\nNow that we have established that the business is ethically responsible for the deaths that occur from the drug even though there is an arms length distance, we can assess commodification limits.\nThere are many things that the general public believes that money should not be able to buy. This means placing a limit on what is able to become a “commodity.” Under this argument there are several moral obligations to take into consideration (Brennan and Jaworski). These would include wrongful exploitation, misallocation, rights violations and paternalism, etc. All of which are semiotic objections meaning that they rely on the idea that markets in certain goods communicate the wrong attitude (Brennan and Jaworski). For the purposes of our argument we will only be looking at paternalism. Paternalism suggests that some markets (like those that deal in drugs) may cause people to make self-destructive choices (Brennan and Jaworski). Euthansia drugs can classify as being relevant in this objection.\nBrennan and Jaworski continue their argument to ultimately state that in reality, semiotic arguments do not stand. The semiotics are just socially constructed and can be changed in order for the commodity to be successfully put into a market (Brennan and Jaworski). Here we can grant that from the first part of their argument, my thesis fails. However, their paper additionally argued in the second half that if a person can do something for free, ultimately they should be able to do it for money (commoditize an object) (Brennan and Joawrski). Here, my argument holds.\nIf it is wrong to do something for free, then it is also wrong to do it for money\nIt is wrong to kill someone for free\nTherefore, it is also wrong to kill someone for money [1,2]\nAs we had established prior, just because a company has an arms length of distance from the administering of their drug does not mean they have less responsibility for killing a person. Because it is not ok to kill someone for free, (assassins, murderers), then it is also not ok to do it for money (companies that produce euthanasia drugs). We have now established that it is not ethically permissible for companies to commoditize euthanasia drugs.\nThis is extremely relevant especially pertaining to Valeant pharmaceuticals who not only sell the euthanasia drug, but price gouge on the drug as well. In this real life instance, the pharmaceutical company actually made it extremely difficult for patients to afford the drug they may have needed very desperately which defeats the argument that companies often make of “we want sick people to have a way out.” By making the drug so excessively expensive they are only putting up barriers for the people who need the drug (Dembosky).\n3. BLAMEWORTHINESS\nThe last part of my argument will discuss the criteria for blameworthiness. To assert blameworthiness we must first grant that the company is an agent (a normal affective being with cognitive capabilities) (Bhargava). Since the company is assumedly made up of fully cognitive human beings we can say that the company is an agent. Next we have to establish whether or not the company had intention (Bhargava).\nIntention is set on a scalar notion where intentionality can be (Bhargava):\nPurposeful (the aim of your action)\nKnowing Reckless (knowing about the risks but you still perform the action)\nNegligence (you should have been aware of the risk)\nSince the company is producing Seconal knowing that the only purpose of the drug is to kill someone, we can say that their intentionality is purposeful as death is the aim of their action.\nThen we must determine if the company is also causally responsible (Bhargava). Here the argument becomes slightly more difficult. In normal examples of being causally responsible, the agent would directly cause the action. Example: an agent rams their car into someone’s home. Because the pharmaceutical company does not physically put the Seconal into a patient’s mouth it can be argued that they are not causally responsible. However, examples of not being causally responsible also do not effectively address our situation. In cases where the person is not causally responsible and only possess intention, the act is not committed by them in any remote manner. For example, Max had intention to kill Michael. Before Max could kill Michael, Ben killed Michael. Max was not causally responsible even though he had intention. I think there is a difference in our situation. Since the company created the drug that they do administer to doctors who use it on patients, they are somewhat causally responsible. This would be the equivalent situation where Max gave the gun to Ben and suggested he use it on Michael. The company is giving the pills to the doctors and saying use it on patients. If Ben had not been given the gun by Max the entire situation would have never happened at all. This implicated Max and does give him a great deal of causality even if it was not direct. Here I grant for these reasons that the drug companies are to some extent causally responsible.\n\nFinally we must conclude that there were no excuses, like being forced into producing the drug (Bhargava). Here I would argue that corporations are normally acting upon free will and motives of profit, there does not seem to be any indication of being forced into producing the drug by external pressure. Because all of these requirements hold, we can conclude that companies responsible for producing euthanasia drugs are also blameworthy for the deaths induced by the drugs.\n4. OBJECTIONS\nThe greatest objection I have received so far has been in regard to other companies that produce deadly products. If we rule out companies being able to produce euthanasia drugs would it not mean we also have to rule out companies with other kinds of deadly products like bleach, guns, knives, gasoline, alcohol etc? While these products can most definitely become deadly to humans, there is one massive distinction. While clorox produces bleach that when ingested can kill you, they are producing the bleach without the intention to kill a human. Bleach is not specifically engineered in order to kill a human nor was it produced for that purpose. The purpose of bleach is to be used as a cleaning product. The same cannot be said for euthanasia drugs. Euthanasia drugs are enginerred with a singular purpose in mind and it is explicitly to kill a human.\nI can see how the argument for guns may be slightly different. Many times guns are specifically used to kill other humans. However, once again they are not manufactured for the sole purpose of killing another human. Guns can be used to kill animals, defensive purposes, or just plain old target practice. Realistically, if a person merely wanted to possess a gun and let it sit in their basement for peace of mind, that would be a reasonable use of that gun. With euthanasia drugs, however, this is not the case. They will be used. They cannot sit around in a basement, be used for defensive purposes and so on. Euthanasia drugs’ only use is to kill a human.\nA second objection I have recieved has been, “how can euthanasia itself be ethically permissible, but not ethically permissible to produce the drug?” I feel as though the best response to this would be this: you are allowed to do anything you’d like to yourself (especially in dire circumstances such as terminal illness), however you would not allow someone else to do anything they’d like to you. For example, if I decided I wanted to take cocaine, then I am allowed to do so. It may be frowned upon, but ultimately it is my own body and I’ll do as I wish. However, if someone else or an outside force played a hand in my decision to take cocaine, that would not be ok with me. I find it is the same with euthanasia. If a person decides that is what they want to do in their last years of terminal illness, they are allowed to do so. However, a company producing and profiting off of that decision is not ethically permissible. The person taking the drug is taking it in order to relieve a great amount of pain and did not decide upon that choice lightly. The distinction is that companies are promoting doing so for the selfish benefit of profit. The two are very different.\nLastly, and what I believe to be the strongest objection, is that businesses are not causally responsible. This is undoubtedly a weaker part of my argument. Ultimately, we must define exactly what causally responsible entails in order to rule out that the business was not in some way causally responsible. I believe in all circumstances, especially in drug circumstances, that businesses play a role in the outcome of what happens to a person after they take the drug. Any product can cause death and companies should know and feel that they played a hand in whatever product caused such grave danger. With cleaning companies, gun companies etc they should work towards making it safer for consumers to use. But in the case of euthanasia drugs there is no way to prevent the death “side effect” and for that reason I believe they are causally responsible because they put the pill in the hand of the consumer.\n5. CONCLUSION\nWhile it is unlikely that businesses will stop producing these drugs on the basis of a philosophical argument on ethics, I think it is important to note the importance of the argument nonetheless. Patients who desperately need these drugs may not be able to afford them which defeats the purpose of them (yet another reason why businesses in the private sector should not be producing the drugs.) Ultimately, it is not ethically permissible for businesses to produce euthanasia drugs even if it euthanasia in itself is ethically permissible. We have examined three distinct theories: Doctrine of Double Effect, commodification limits and blameworthiness criterion in order to separately support my claims. Regardless of which theory is ultimately used, (individually or in tandem) each has demonstrated in different manners that production of and profit from such drugs is ethically impermissible. Businesses failed to prove ethically redeemable qualities in producing the drugs in order meet the criteria for the Doctrine. Businesses failed to be classified as a marketable commodity. But most importantly, businesses succeeded in meeting the criteria for blameworthiness for user’s death.\nWorks Cited Bhargava, Vikram. “Blameworthiness.” In Class.\nBrennan, Jason, and Peter Martin Jaworski. “Markets without Symbolic Limits.” Ethics, vol. 125, no. 4, The University of Chicago Press, 2015, pp. 1053–77, https://doi.org/10.1086/680907.\nCourt, Emma. “Valeant Gets a New Name to Shed Its Scandals, but Will It Work?” MarketWatch, MarketWatch, 17 July 2018, www.marketwatch.com/story/valeant-will-get-a-new-name-again-hoping-to-shed-its-scandals-2018-05-08. Dembosky, April. “Drug Company Jacks Up Cost Of Aid-In-Dying Medication.” NPR, NPR, 23 Mar. 2016, www.npr.org/sections/health-shots/2016/03/23/471595323/drug-company-jacks-up-cost-of-aid-in-dying-medication. Jesse C. Vivian, RPh. “Lethal Injections, Drug Shortages, and Pharmacy Ethics.” U.S. Pharmacist – The Leading Journal in Pharmacy, 18 Oct. 2013, www.uspharmacist.com/article/lethal-injections-drug-shortages-and-pharmacy-ethics-44470. Masek, Lawrence. “The Doctrine of Double Effect, Deadly Drugs, and Business Ethics.” Business Ethics Quarterly, vol. 10, no. 2, Cambridge University Press, 2000, pp. 483–95, https://doi.org/10.2307/3857887.\nMcIntyre, Alison. “Doctrine of Double Effect.” Stanford Encyclopedia of Philosophy, Stanford University, 24 Dec. 2018, plato.stanford.edu/entries/double-effect/#applications."
  },
  {
    "objectID": "va_elex_project/01_virginia_election_project_datawrangling.html",
    "href": "va_elex_project/01_virginia_election_project_datawrangling.html",
    "title": "Virginia Election Project",
    "section": "",
    "text": "Data available here: https://historical.elections.virginia.gov/elections/view/144567/\nA little column cleaning and we’ll load in the data file.\n\nprez_2020 <- read_csv(\"processed_data/va_2020_prez_cleaned.csv\")\n\nRows: 134 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): locality\nnum (3): biden, trump, total_votes_2021_prez\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLet’s see what we have\n\nhead(prez_2020) \n\n# A tibble: 6 × 4\n  locality         biden trump total_votes_2021_prez\n  <chr>            <dbl> <dbl>                 <dbl>\n1 Accomack County   7578  9172                 16962\n2 Albemarle County 42466 20804                 64657\n3 Alexandria City  66240 14544                 82508\n4 Alleghany County  2243  5859                  8203\n5 Amelia County     2411  5390                  7893\n6 Amherst County    5672 11041                 17005\n\n\nCalculating percentage of the vote\n\nprez_2020 %>% \n  mutate(\n    biden_pct = biden/total_votes_2021_prez\n  )\n\n# A tibble: 134 × 5\n   locality           biden trump total_votes_2021_prez biden_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962     0.447\n 2 Albemarle County   42466 20804                 64657     0.657\n 3 Alexandria City    66240 14544                 82508     0.803\n 4 Alleghany County    2243  5859                  8203     0.273\n 5 Amelia County       2411  5390                  7893     0.305\n 6 Amherst County      5672 11041                 17005     0.334\n 7 Appomattox County   2418  6702                  9268     0.261\n 8 Arlington County  105344 22318                130699     0.806\n 9 Augusta County     10840 30714                 42278     0.256\n10 Bath County          646  1834                  2501     0.258\n# … with 124 more rows\n\n\nNow let’s do some rounding and move that decimal point\n\nprez_2020 %>% \n  mutate(\n    biden_pct = janitor::round_half_up(biden / total_votes_2021_prez * 100, 1)\n  )\n\n# A tibble: 134 × 5\n   locality           biden trump total_votes_2021_prez biden_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962      44.7\n 2 Albemarle County   42466 20804                 64657      65.7\n 3 Alexandria City    66240 14544                 82508      80.3\n 4 Alleghany County    2243  5859                  8203      27.3\n 5 Amelia County       2411  5390                  7893      30.5\n 6 Amherst County      5672 11041                 17005      33.4\n 7 Appomattox County   2418  6702                  9268      26.1\n 8 Arlington County  105344 22318                130699      80.6\n 9 Augusta County     10840 30714                 42278      25.6\n10 Bath County          646  1834                  2501      25.8\n# … with 124 more rows\n\n\nNow trump too\n\nprez_2020 <- prez_2020 %>% \n  mutate(\n    biden_pct = janitor::round_half_up(biden / total_votes_2021_prez * 100, 2),\n    trump_pct = janitor::round_half_up(trump / total_votes_2021_prez * 100, 2)\n  )\n\nhead(prez_2020)\n\n# A tibble: 6 × 6\n  locality         biden trump total_votes_2021_prez biden_pct trump_pct\n  <chr>            <dbl> <dbl>                 <dbl>     <dbl>     <dbl>\n1 Accomack County   7578  9172                 16962      44.7      54.1\n2 Albemarle County 42466 20804                 64657      65.7      32.2\n3 Alexandria City  66240 14544                 82508      80.3      17.6\n4 Alleghany County  2243  5859                  8203      27.3      71.4\n5 Amelia County     2411  5390                  7893      30.6      68.3\n6 Amherst County    5672 11041                 17005      33.4      64.9"
  },
  {
    "objectID": "va_elex_project/01_virginia_election_project_datawrangling.html#reshaping",
    "href": "va_elex_project/01_virginia_election_project_datawrangling.html#reshaping",
    "title": "Virginia Election Project",
    "section": "Reshaping",
    "text": "Reshaping\nEnter pivot_wider().\nWe’ll get rid of everything we don’t need first.\n\ngov_2021 <- gov_2021 %>% \n  filter(ballot_name %in% c(\"Glenn A. Youngkin\", \"Terry R. McAuliffe\")) %>% \n  select(-locality_code,\n         -political_party)\n  \ngov_2021\n\n# A tibble: 266 × 4\n   locality_name    ballot_name        votes percentage\n   <chr>            <chr>              <int> <chr>     \n 1 ACCOMACK COUNTY  Glenn A. Youngkin   7878 61.08%    \n 2 ACCOMACK COUNTY  Terry R. McAuliffe  4948 38.37%    \n 3 ALBEMARLE COUNTY Glenn A. Youngkin  19141 37.21%    \n 4 ALBEMARLE COUNTY Terry R. McAuliffe 31919 62.05%    \n 5 ALEXANDRIA CITY  Glenn A. Youngkin  14013 24.02%    \n 6 ALEXANDRIA CITY  Terry R. McAuliffe 43866 75.20%    \n 7 ALLEGHANY COUNTY Glenn A. Youngkin   4530 74.52%    \n 8 ALLEGHANY COUNTY Terry R. McAuliffe  1518 24.97%    \n 9 AMELIA COUNTY    Glenn A. Youngkin   4720 74.19%    \n10 AMELIA COUNTY    Terry R. McAuliffe  1617 25.42%    \n# … with 256 more rows\n\n\nNow we’ll do the spreading out to reshape.\n\ngov_2021_wide <- gov_2021 %>% \n  pivot_wider(names_from = ballot_name, values_from = c(votes, percentage))\n\ngov_2021_wide\n\n# A tibble: 133 × 5\n   locality_name     `votes_Glenn A. Youngkin` votes_Terry R. …¹ perce…² perce…³\n   <chr>                                 <int>             <int> <chr>   <chr>  \n 1 ACCOMACK COUNTY                        7878              4948 61.08%  38.37% \n 2 ALBEMARLE COUNTY                      19141             31919 37.21%  62.05% \n 3 ALEXANDRIA CITY                       14013             43866 24.02%  75.20% \n 4 ALLEGHANY COUNTY                       4530              1518 74.52%  24.97% \n 5 AMELIA COUNTY                          4720              1617 74.19%  25.42% \n 6 AMHERST COUNTY                         9731              3897 71.00%  28.43% \n 7 APPOMATTOX COUNTY                      5971              1438 80.26%  19.33% \n 8 ARLINGTON COUNTY                      21548             73013 22.63%  76.67% \n 9 AUGUSTA COUNTY                        26196              7231 77.93%  21.51% \n10 BATH COUNTY                            1539               396 79.04%  20.34% \n# … with 123 more rows, and abbreviated variable names\n#   ¹​`votes_Terry R. McAuliffe`, ²​`percentage_Glenn A. Youngkin`,\n#   ³​`percentage_Terry R. McAuliffe`\n\n\nNice.\nThis is giving us some pretty long column names. we can change them after the fact using rename(). But first let’s clean the names to make it easier.\n\ngov_2021_wide <- gov_2021_wide %>% \n  clean_names()\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    votes_glenn_a_youngkin votes_terry_r_mc_aul…¹ perce…² perce…³\n  <chr>                             <int>                  <int> <chr>   <chr>  \n1 ACCOMACK COUNTY                    7878                   4948 61.08%  38.37% \n2 ALBEMARLE COUNTY                  19141                  31919 37.21%  62.05% \n3 ALEXANDRIA CITY                   14013                  43866 24.02%  75.20% \n4 ALLEGHANY COUNTY                   4530                   1518 74.52%  24.97% \n5 AMELIA COUNTY                      4720                   1617 74.19%  25.42% \n6 AMHERST COUNTY                     9731                   3897 71.00%  28.43% \n# … with abbreviated variable names ¹​votes_terry_r_mc_auliffe,\n#   ²​percentage_glenn_a_youngkin, ³​percentage_terry_r_mc_auliffe\n\n\nNow let’s rename, and we’ll use similar names to what we had earlier in our 2021 results.\n\ngov_2021_wide <- gov_2021_wide %>% \n  rename(\n    youngkin = votes_glenn_a_youngkin,\n    mcauliffe = votes_terry_r_mc_auliffe,\n    pct_youngkin = percentage_glenn_a_youngkin,\n    pct_mcauliffe = percentage_terry_r_mc_auliffe\n  )\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>               <int>     <int> <chr>        <chr>        \n1 ACCOMACK COUNTY      7878      4948 61.08%       38.37%       \n2 ALBEMARLE COUNTY    19141     31919 37.21%       62.05%       \n3 ALEXANDRIA CITY     14013     43866 24.02%       75.20%       \n4 ALLEGHANY COUNTY     4530      1518 74.52%       24.97%       \n5 AMELIA COUNTY        4720      1617 74.19%       25.42%       \n6 AMHERST COUNTY       9731      3897 71.00%       28.43%       \n\n\nBingo.\nThere’s still one potential issue here. Can you see it?\nThe percentage columns are actually text values, not numbers. And they have that % sign in the text too. Let’s fix that using a handy function from the readr package, parse_number().\n\ngov_2021_wide <- gov_2021_wide %>% \n  mutate(\n    pct_youngkin = readr::parse_number(pct_youngkin),\n    pct_mcauliffe = readr::parse_number(pct_mcauliffe)\n  )\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>               <int>     <int>        <dbl>         <dbl>\n1 ACCOMACK COUNTY      7878      4948         61.1          38.4\n2 ALBEMARLE COUNTY    19141     31919         37.2          62.0\n3 ALEXANDRIA CITY     14013     43866         24.0          75.2\n4 ALLEGHANY COUNTY     4530      1518         74.5          25.0\n5 AMELIA COUNTY        4720      1617         74.2          25.4\n6 AMHERST COUNTY       9731      3897         71            28.4\n\n\nPerfect. Problem solved."
  },
  {
    "objectID": "va_elex_project/01_virginia_election_project_datawrangling.html#comparing-gov-vs.-prez-results",
    "href": "va_elex_project/01_virginia_election_project_datawrangling.html#comparing-gov-vs.-prez-results",
    "title": "Virginia Election Project",
    "section": "Comparing gov vs. prez results",
    "text": "Comparing gov vs. prez results\nNow that things are join, let’s actually go ahead and start making columns to compare the two elections and how the candidates did this time compared with last time.\nWhere should we go from here….?"
  },
  {
    "objectID": "va_elex_project/02_virginia_election_project_youranalysis.html",
    "href": "va_elex_project/02_virginia_election_project_youranalysis.html",
    "title": "Virginia Election Project",
    "section": "",
    "text": "Comparing Virgnia Gov vs. Prez\n\n\ncompates governor race R to D\n\n\ncompares governor candidates to presidentail 2020\n#Yungkin vs. trump #MC vs biden #at least two tables and two charts\n\n#compares governor race R to D\nhead(joined_vacomparison)\n\n# A tibble: 6 × 9\n  locality         biden trump biden_pct trump…¹ young…² mcaul…³ pct_y…⁴ pct_m…⁵\n  <chr>            <dbl> <dbl>     <dbl>   <dbl>   <int>   <int>   <dbl>   <dbl>\n1 ACCOMACK COUNTY   7578  9172      44.7    54.1    7878    4948    61.1    38.4\n2 ALBEMARLE COUNTY 42466 20804      65.7    32.2   19141   31919    37.2    62.0\n3 ALEXANDRIA CITY  66240 14544      80.3    17.6   14013   43866    24.0    75.2\n4 ALLEGHANY COUNTY  2243  5859      27.3    71.4    4530    1518    74.5    25.0\n5 AMELIA COUNTY     2411  5390      30.6    68.3    4720    1617    74.2    25.4\n6 AMHERST COUNTY    5672 11041      33.4    64.9    9731    3897    71      28.4\n# … with abbreviated variable names ¹​trump_pct, ²​youngkin, ³​mcauliffe,\n#   ⁴​pct_youngkin, ⁵​pct_mcauliffe\n\njoined_vacomparison <- joined_vacomparison %>% \nmutate(gov_r_win = pct_youngkin - pct_mcauliffe)\n\ngov_r_win_joined_vacomparison <- joined_vacomparison %>% \n  arrange(desc(gov_r_win)) %>%\n  head(10) \n\n\nggplot(gov_r_win_joined_vacomparison, aes(x = reorder(locality, -gov_r_win), y = gov_r_win)) +\n    geom_col() \n\n\n\n\n\njoined_vacomparison <- joined_vacomparison %>% \nmutate(d_gov_to_pres = pct_mcauliffe - biden_pct)\n\nd_gov_to_pres_joined_vacomparison <- joined_vacomparison %>% \n  arrange(desc(d_gov_to_pres)) %>%\n  head(10) \n\n\nggplot(d_gov_to_pres_joined_vacomparison, aes(x = reorder(locality, -d_gov_to_pres), y = d_gov_to_pres)) +\n    geom_col() \n\n\n\n\n\njoined_vacomparison <- joined_vacomparison %>% \nmutate(Rgov_to_pres = pct_youngkin - trump_pct)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Katie Coolidge",
    "section": "",
    "text": "---\nHi, I’m Katie and I’m a senior business student at the George Washington University. I am concentrating in finance with a minor in journalism and mass communication. My unique intersection of skills has opened me up to unique interests in financial markets and trends.\n---"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Katie Coolidge",
    "section": "Education",
    "text": "Education\nGeorge Washington University"
  },
  {
    "objectID": "index.html#work-experience",
    "href": "index.html#work-experience",
    "title": "Katie Coolidge",
    "section": "Work Experience",
    "text": "Work Experience\nWIFA\nGWTV\nEllen Lange Skincare\nEvercore ISI"
  },
  {
    "objectID": "index.html#skills",
    "href": "index.html#skills",
    "title": "Katie Coolidge",
    "section": "Skills",
    "text": "Skills\nWriting\nPublic Speaking\nExcel\nBloomberg"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Welcome to Katie Coolidge’s website. Here I will be sharing my skills, background, resume and examples of previous work.\nA digital resume!\nSo thankful for Professor Kessler at SMPA for teaching me how to code R in order to make this awesome website to showcase all my skills!"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "Jack Carlson\nMy first piece is an article feature on Jack Carlson, the founder of clothing company Rowing Blazers. I conducted the interview during the height of covid when the magazine’s theme was to feature stories about globalization. I decided to conduct my piece on the opposite– featuring a clothing brand striving to preserve a dynamic preppy audience.\n\nAstrid Voss\nMy second piece features a high school fashion model from Massachusetts who walked for Burberry during their virtually broadcasted show during covid. The article attempts to capture the experience of working for world renowned fashion houses when the typical environment changed drastically.\n\nNew Balance\nMy third piece is based off of a paper I wrote for a college marketing class. The goal was to find a company caught in an interesting part of the product life cycle. New Balance was featured because in 2021 they were experiencing a large overhaul in brand image and marketing.\nPlease find the hyperlinks to each article below:"
  },
  {
    "objectID": "profilepiece.html",
    "href": "profilepiece.html",
    "title": "Profile Piece",
    "section": "",
    "text": "In my intro to news writing class I wrote a piece on my close friend’s mother who had an amazing career that I admired.\nShe was a talent agent for a bunch of very famous companies that at various points were bicoastal and allowed her to attend very glamorous events.\n\nProfile: Geri Campbell\nCelebrities will always procure a certain fascination from the populace. But, according to Geri Campbell, many times their world was enclosed by a thin, shimmering veneer; and it was her job to create it as a talent agent.\n“Truth be told I wanted to be an actor,” Campbell said while nestled into her couch with pet schnauzer in tow.\nInstead, she got as close as humanly possible to celebrities.\nEntertainment Editor, Special Projects Director and Celebrity Talent Producer were titles held by Campbell. Reese Witherspoon, Kate Moss and Julia Roberts were household names in her family. Campbell’s job was to procure talent. She would work in tandem with renowned publications and photographers to create, book and capture celebrities. Magazine covers, reality TV and movie reviews were not weekend hobbies, but components of her professional life.\nInspiration for her career first stemmed from magazines and television. Campbell was charmed by anything with a fashionable female lead: “Bewitched” and “That Girl.”\nThis interest was later fostered by her step-dad, Sam Novenstern, who was head of broadcasting for Madison Square Garden. The New York Knicks and Rangers would frequent her house for dinner.\n“I was a fun friend to have in high school because I would take friends to concerts or games at Madison Square Garden,” she said.\nAfter high school, Campbell went on to study communications at Boston University. While in undergrad she became the creative director of AdLab, a student run ad agency. Campbell’s pinnacle moment was creating the infamous “neighborhood watch eye” that is still in use today.\nWhile Boston was great for school, the second Campbell graduated she rushed back to New York, her favorite city. Her first job was for Diener Hauser Bates Advertising, whom she had previously worked for over the summers. There, she wrote taglines and trailers for major motion pictures at just 23.\nEven though she enjoyed her experience at Bates, Campbell was constantly changing jobs. The industry, while idealized, is extremely volatile. However, no industry more so than fashion: exactly where Campbell ended up. Mirabella Magazine, run by Grace Mirabella, became Campbell’s “war of the worlds.” Blood and stiff competition ran deep between Vogue and Mirabella making Campbell’s job a nightmare. As a model editor, she needed to book the models. That’s not an easy thing to do when you have Vogue undermining your efforts. Campbell adapted to the challenge. She iconically spearheaded the movement of putting actresses on magazine covers.\n“We couldn’t get the models we were used to working with…so I put Julia Roberts on the cover because no one wanted them at the time.”\nBesides practically inventing the celebrity cover movement, Campbell was a founding editor at Allure magazine, opened her own production company and was the director of talent for VH1. Even though she’s played many roles in life, the one that makes her most proud is being a mother.\nCampbell’s legendary career will likely live on through her 21-year-old daughter, Nathalie, who also wants to be a talent agent. Campbell raised Nathalie between two coasts, L.A. and Bedford, NY, while juggling her job for VH1. Campbell fought both Condé Nast and Viacom relentlessly to work two days from home in order to raise her daughter. It was previously unheard of.\n“I helped to change policy by doing that,” she said.\nIt was one of her proudest moments.\nThe two of them are about as similar as can be. But, Campbell voiced her doubts. The job is constantly about making the impossible possible. She admitted the job made her meaner.\n“You had to be [mean]. People were irrational and difficult about things completely out of your control,” she said.\nIn her old office, Campbell hung a sign saying “no, Grace Kelly is not available” because there was truly no ask that was too crazy.\nDespite the challenges, her career also taught her not to take things so seriously. Yes, the drama was ridiculous, but the world Campbell entertained was completely illusory. She saw supermodels with no makeup, actresses not in character. Sometimes that was extraordinary, but other times would fall short of expectations.\n“I did a lot for people in the industry…there are a lot of people and models that I gave their first job to. I’m not legendary in any way, but in those ways I made a mark,” she said.\nShe was the magician behind the glittering facade we see on magazine covers and television. Her job was to always make fantasy a reality. And she did a pretty good job.\n."
  },
  {
    "objectID": "walkthrough.html",
    "href": "walkthrough.html",
    "title": "Georgia Analysis Walkthrough",
    "section": "",
    "text": "We will start by loading our libraries in order to run future lines of code. The libraries are packages that allow the code we will write to run properly (giving the code the proper tools).\nHere, I loaded my Georgia votes into my R from the excel spreadsheet by running the code read_excel. This prompts R to open up whatever excel file I put inside the here() which is the Georgia Votes excel sheet.\nThen, I wanted to differentiate what parts of the excel file were important. First I wanted the code to show the senate results, so I pulled ONLY the senate sheet from the excel code by using sheet = “senate”.\nNext I wanted the governor results so I pulled only the governor sheet in the same manner by using sheet = “governor” inside the read_excel function.\n\n\nCode\n#import the GA election data for this assignment\n\n#GA senate\nsenate_results <- read_excel(here(\"ga_votes.xlsx\"), sheet = \"senate\")\n\n#GA governor\ngovernor_results <- read_excel(here(\"ga_votes.xlsx\"), sheet = \"governor\")\n\n\nTwo columns in particular to highlight that we’ll use to examine how the Republican Senate and Governor candidates did compared with former President Trump’s performance in 2020:\n\npct_r_above_trump. This column calculates the difference in percentage points between what the 2022 Republican candidate got (pct_r_2022) and what Trump got two years earlier (pct_r_2020). A negative value means the candidate did worse than Trump, a positive value means they did better.\nis_r_above_trump. This companion columns is a so-called “flag” column, which provides a Yes/No as to whether the Republican candidate did better or worse than Trump. In other words, is the pct_r_above_trump value positive or negative.\n\nNext, I created a column chart that shows how many counties the Republican senate candidates did better vs. worse than Trump. Better meaning the value will be positive if they candidate did better and negative if they did worse.\nIn doing this I used ggplot() to pull the senate_results data then wanted the x axis of my bar chart to be the counties so I used the label inside the dataset called “county” and the height of the columns to be the percent above trump of the winning candidate.\nThen I renamed the axis using scale_y_continuous and scale_x_discrete to use more appropriate labels. Then, I added a title of the graph using labs(title =\nI then used geomcol() to actually create the bar chart based on the data I pulled.\n\n\nCode\nggplot(senate_results, aes(x = county, y = pct_r_above_trump)) +\n    scale_y_continuous(name = \"Percent Above Trump\", labels = scales::comma) +\n  scale_x_discrete(name = \"County\") +\n  labs(title = \"Republican Senate Candidates that Did Better or Worse than Trump\") +\n  geom_col()\n\n\n\n\n\nNext I made the same chart for the race for Governor with the same code as above only I switched the data to pull instead from governor_results.\n\n\nCode\nggplot(governor_results, aes(x = county, y = pct_r_above_trump)) +\n    scale_y_continuous(name = \"Percent Above Trump\", labels = scales::comma) +\n  scale_x_discrete(name = \"County\") +\n  labs(title = \"Republican Governor Candidates that Did Better or Worse than Trump\") +\n  geom_col()\n\n\n\n\n\nFor the Senate race, I created a chart that shows the top 10 biggest drops between the Republican candidate and Trump.\nFirst, I renamed/made a new copy of the dataset to new_senate_results as not to mess with the original called “senate_results”.\nThen by using arrange(desc()), I was able to order the candidates in descending order (greatest to least) to find the biggest drops between the Republican candidate and Trump.\nIn order to just use the top 10, I needed to use the head() function and put 10 in the parenthesis to tell it I only want the first 10 of that list I made.\nNext, in order to make this data into a bar chart I needed to use ggplot() again. Here I inputted the dataset where this information was stored, which we said I named new_senate_results earlier. Then so that the bars are in the first quadrant and positive numbers, I needed to do something new with the x axis labeling.\nInstead of the code just being aes(x = county) now it has to be aes(x = reorder(x value, -y value)) so that It flips the y values upright and makes the graph look neater. Then I entered in the typical argument for y = pct_r_above_trump so that the y axis will show how much the candidate did better or worse than Trump.\nThen I renamed the axis using scale_y_continuous and scale_x_discrete to use more appropriate labels. Then, I added a title of the graph using labs(title =\n\n\nCode\nnew_senate_results <- senate_results %>% \n  arrange(desc(pct_r_above_trump)) %>%\n  head(10) \n\n\nggplot(new_senate_results, aes(x = reorder(county, -pct_r_above_trump), y = pct_r_above_trump)) +\n    scale_y_continuous(name = \"Percent Above Trump\", labels = scales::comma) +\n  scale_x_discrete(name = \"County\") +\n  labs(title = \"Top 10 biggest drops between the Republican Senate Candidate and Trump\") +\n  geom_col() \n\n\n\n\n\nFor the Senate race, I created a chart that shows the top 10 counties highest margins of victory for the Democratic candidate. Note: in order to calculate the margin of victory you will subtract the republican results from the democrat results in 2022.\nSo in order to get this new column inside the dataset, first make a new copy which I named margin_of_victory_data from the original senate_results data. Then you have to use the function mutate() in order to add a new column. Inside mutate I put (pct_d_2022 - pct_r_2022) in order to calculate the margin of victory. Once you run this line of code a new column should appear in margin_of_victory_data named MOV as I named it in the code.\nI then made another copy of the dataset named margin_of_victory_senate to specify that the data was for the senate. After this I arranged the margin of victory data, MOV column, in descending order by using arrange(desc).\nMy last dataset I named top_ten_MOV which took the data we just made margin_of_victory_senate and headed it by 10 or gave me only the top 10 results.\nThen I used ggplot() in the same way we used before to take my data top_ten_MOV and make it into a bar chart with geom_col(). I wanted my x axis to be counties again but needed to reorder so that the chart was positive y values, using aes(x = reorder(county, -MOV)) and then my y axis to show the data we just created from margin of victory – MOV.\nThen I renamed the axis using scale_y_continuous and scale_x_discrete to use more appropriate labels. Then, I added a title of the graph using labs(title =\n\n\nCode\nlibrary(dplyr)\nmargin_of_victory_data <- senate_results %>% \n  mutate(MOV = (pct_d_2022 - pct_r_2022))\n\nmargin_of_victory_senate <- margin_of_victory_data %>% \n  arrange(desc(MOV))\n\ntop_ten_MOV <- head(margin_of_victory_senate,10)\n\nggplot(top_ten_MOV, aes(x = reorder(county, -MOV), y = MOV)) +\n  scale_y_continuous(name = \"Margin of Victory (D-R)\", labels = scales::comma) +\n  scale_x_discrete(name = \"County\") +\n  labs(title = \"D vs. R Senate Margin of Victory\") +\n  geom_col()\n\n\n\n\n\nHere, I did the same as the previous lines of code but for the race for governor.\n\n\nCode\nmargin_of_victory_data_2 <- governor_results %>% \n  mutate(MOV_governor = (pct_d_2022 - pct_r_2022))\n\nmargin_of_victory_governor <- margin_of_victory_data_2 %>% \n  arrange(desc(MOV_governor))\n\ntop_ten_MOV_gov <- head(margin_of_victory_governor,10)\n\nggplot(top_ten_MOV_gov, aes(x = reorder(county, -MOV_governor), y = MOV_governor)) +\n  scale_y_continuous(name = \"Margin of Victory (D-R)\", labels = scales::comma) +\n  scale_x_discrete(name = \"County\") +\n  labs(title = \"D vs. R Governor Margin of Victory\") +\n  geom_col()\n\n\n\n\n\nI used tmap to create maps in this section.\nTo help start things out for you, we’re going to download a geospatial/map dataset with the county boundaries for Georgia. We’ll use the tigris package to do this.\n\n\nCode\ncounties_geo <- tigris::counties(state = \"GA\", resolution = \"20m\", cb = TRUE)\n\n\nRetrieving data for the year 2020\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  51%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |======================================================================| 100%\n\n\nNow let’s take a look at what we have, by mapping out the polygons of the Georgia counties using the tmap package.\nFirst, I used tm_shape to get all of the counties shapes loaded into my R for Georgia. Then I used tm_polygons in order to put the counties into a graphical representation as seen below.\n\n\nCode\ntm_shape(counties_geo) + \n  tm_polygons()\n\n\n\n\n\nFor the Senate race, I created a choropleth (shaded) map of Georgia counties that shows where the Republican candidate for Senate did better vs. worse than Trump.\nI did this by joining my geographical county data “counties_geo” and the “senate_results” by joining the two by GEOID and fipscode to create a new dataset which I called senatemap.\nThen I used tm_shape to create a chloropleth map by pulling from the data I just created, senatemap. Then I used tm_poygons to say that I wanted to take data from the “is_r_above_trump” column to show one color if they did better and another if they did worse than Trump and then link that with the GEOID so that it can create the geographical chart.\n\n\nCode\nsenatemap <- inner_join(counties_geo, senate_results, by = c(\"GEOID\" = \"fipsCode\"))\n\ntmap_mode(mode = \"plot\")\n\n\ntmap mode set to plotting\n\n\nCode\ntm_shape(senatemap) +\n  tm_polygons(\"is_r_above_trump\", id = \"GEOID\")\n\n\n\n\n\nNow I’ve done the same as above, but for the GOVERNOR race.\n\n\nCode\ngovmap <- inner_join(counties_geo, governor_results, by = c(\"GEOID\" = \"fipsCode\"))\n\ntmap_mode(mode = \"plot\")\n\n\ntmap mode set to plotting\n\n\nCode\ntm_shape(govmap) +\n  tm_polygons(\"is_r_above_trump\", id = \"GEOID\")\n\n\n\n\n\nFor the Senate race, I created a choropleth map that shows the margins of victory for the Democratic candidate.\nTo do that I needed to compare the Democratic candidate’s percentage (pct_d_2022) with the Republican’s (pct_r_2022) to calculate the margin of victory for each county.Good thing this column of data already exists under my dataset named margin_of_victory_senate, which I used to inner join with counties_geo by fipscode.\nThis created a new dataset I named MOVsenmap. From here I wanted to take MOVsenmap and actually make a map using that column MOV. To do this I did tm_shape and used MOVsenmap data, then used tm_polygons to use the MOV column I created in the data with the grographical location GEOID to create the map.\n\n\nCode\nMOVsenmap <- inner_join(counties_geo, margin_of_victory_senate, by = c(\"GEOID\" = \"fipsCode\"))\n\ntmap_mode(mode = \"plot\")\n\n\ntmap mode set to plotting\n\n\nCode\ntm_shape(MOVsenmap) +\n  tm_polygons(\"MOV\", id = \"GEOID\")\n\n\nVariable(s) \"MOV\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nNow I did the same as above, but this time for the GOVERNOR race.\n\n\nCode\nMOVgovmap <- inner_join(counties_geo, margin_of_victory_governor, by = c(\"GEOID\" = \"fipsCode\"))\n\ntmap_mode(mode = \"plot\")\n\n\ntmap mode set to plotting\n\n\nCode\ntm_shape(MOVgovmap) +\n  tm_polygons(\"MOV_governor\", id = \"GEOID\")\n\n\nVariable(s) \"MOV_governor\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "va_election_walkthrough.html",
    "href": "va_election_walkthrough.html",
    "title": "Virginia Election Code Walkthrough",
    "section": "",
    "text": "1 Intro: Here I will be using Virginia election data from the race between Biden and Trump but also the race for Governor between Terry McAuliffe and Glenn Youngkin.\nWe will use the data throughout this walkthrough to show several comparisons between candidates of each race.\nNow we will run the appropriate libraries in order to run future lines of code:\n\nHere we will be making a broad datatable from the election information so that you can search through and play with the different arguments.\n\nFirst I took my dataset with all the information, joined_vacomparison and made a searchable data table by using DT::datatable function and making sure I put in a filter argument = “top” to let a viewer search by the top labels.\n\njoined_vacomparison %>% \n  DT::datatable(rownames = FALSE, filter = \"top\",\n                options = list(searching = FALSE, paging = FALSE, dom = \"tip\")) \n\n\n\n\n\n\n3 & 4: Ultimately, this code will show us a chart of the top 5 counties with the highest differences between Youngkin and Trump percentages.\nTo do this, first I had to make a new column to calculate the difference between the percentage of the Youngkin vote and Trump vote by using mutate(), picking a name for the column, Rgov_to_pres and giving them the calculation, pct_youngkin - trump_pct. Then I arranged this data in descending order (greatest to least).\nNow, I only want the top 5. I made a new dataset called top_5_counties_youngkin_v_trump to cut off my original dataset Rgov_to_pres_joined_vacomparison to only 5 values by using head().\nThen to create the chart I used ggplot() and picked the new data set I created of just the top 5 counties, top_5_counties_youngkin_v_trump and made sure to reorder my input so that the y values would be in the first quadrant and not negative numbers. I wanted x=locality and y = the values from the new column we made calculating the difference in percent between youngkin and trump. Therefore, x = reorder(locality, -Rgov_to_pres, y = Rgov_to_pres).\nI then flipped the coordinates so that all of the county names show up clearly and non-overlapped with coord_flip(). Then I renamed the axis using scale_y_continuous and scale_x_discrete to use more appropriate labels. Then, I added a title of the graph using labs(title =\nThen I used geom(col) to make the bar chart to show it.\n\nRgov_to_pres_joined_vacomparison <- joined_vacomparison %>% \nmutate(Rgov_to_pres = pct_youngkin - trump_pct) %>% \n  arrange(desc(Rgov_to_pres))\n\ntop_5_counties_youngkin_v_trump <- head(Rgov_to_pres_joined_vacomparison,5)\n\nggplot(top_5_counties_youngkin_v_trump, aes(x = reorder(locality, -Rgov_to_pres), y = Rgov_to_pres)) +\n  coord_flip() +\n    scale_y_continuous(name = \"Youngkin Performance Against Trump\", labels = scales::comma) +\n  scale_x_discrete(name = \"County\") +\n  labs(title = \"Top 5 Counties with Biggest Difference Between Youngkin & Trump\") +\n  geom_col() \n\n\n\n\n\nHere I wanted to create a chart that shows the top 5 counties where Youngkin got the highest percentage of the vote.\n\nTo do this first I made a new dataset named top_5_youngkin_counties by only including the two columns I needed – locality and the percent of youngkins vote select(locality, pct_youngkin). Then, I arranged these values in descending order with arrange(desc()) and only took the top 5 by using head(5).\nIn order to make a bar chart of the top 5 results I had to use ggplot() to select the new dataset, top_5_youngkin_counties. I needed to reorder the x so that my y values would show up cleanly so I used locality for my x value and the percent of youngkin votes as the y “pct_youngkin”.\nI then flipped the coordinates so that all of the county names show up clearly and non-overlapped with coord_flip(). Then I renamed the axis using scale_y_continuous and scale_x_discrete to use more appropriate labels. Then, I added a title of the graph using labs(title =\nThen, I used geom_col() to make the bar chart of the data.\n\ntop_5_youngkin_counties <- joined_vacomparison %>% \n  select(locality, pct_youngkin) %>%\n   arrange(desc(pct_youngkin)) %>% \n  head(5)\n\nggplot(top_5_youngkin_counties, aes(x = reorder(locality, -pct_youngkin), y = pct_youngkin)) +\n    coord_flip() +\n  scale_y_continuous(name = \"Percent Vote Youngkin\", labels = scales::comma) +\n  scale_x_discrete(name = \"County\") +\n  labs(title = \"Top 5 Youngkin Counties Votes\") +\n  geom_col() \n\n\n\n\n\nHere I wanted to create a TABLE that shows the top 5 counties where McAuliffe got the highest percent of the vote.\n\nTo do this first I made a new dataset names top_5_mcauliffe_counties from my original dataset joined_vacomparison. In the new dataset I selected only the two fields I needed which where locality and pct_mcauliffe. Then I arranged them in descending order by using arrange(desc(pct_mcauliffe)) and head(5) to only take the top 5.\nFrom here I made my table using DT:: datatable and inputted the dataset I wanted to make a table which was top_5_mcauliffe_counties.\n\ntop_5_mcauliffe_counties <- joined_vacomparison %>% \n  select(locality, pct_mcauliffe) %>%\n   arrange(desc(pct_mcauliffe)) %>% \n  head(5)\n\nDT::datatable(top_5_mcauliffe_counties)\n\n\n\n\n\n\n\nIn this segment I wanted to compare the 2 candidates for governor.\n\nFirst, I had to add a new column to joined_vacomparison to compare the percent vote of youngkin to mcauliffe. I did this by using the function mutate() and giving them the equation to find the difference = pct_youngkin - pct_mcauliffe.\nThen I renamed the dataset to be more specific to gov_r_win_joined_vacomparison and arranged the new column that I created (gov_r_win) in descending order using arrange(desc(govr_r_win)). Then I only wanted the top 10 so I headed it, head(10).\nIn order to create the chart of this I used ggplot() and selected the dataset I needed – gov_r_win_joined_vacomparison, and then told ggplot what would be in my x and y axis, x = locality and y = gov_r_win. In order to format it nicely I used reorder to make sure my y values were in the first quadrant.\nI then flipped the coordinates so that all of the county names show up clearly and non-overlapped with coord_flip(). Then I renamed the axis using scale_y_continuous and scale_x_discrete to use more appropriate labels. Then, I added a title of the graph using labs(title =\nThen I used geom(col) to make the actual chart.\n\n#compares governor race R to D\n\njoined_vacomparison <- joined_vacomparison %>% \nmutate(gov_r_win = pct_youngkin - pct_mcauliffe)\n\ngov_r_win_joined_vacomparison <- joined_vacomparison %>% \n  arrange(desc(gov_r_win)) %>%\n  head(10) \n\n\nggplot(gov_r_win_joined_vacomparison, aes(x = reorder(locality, -gov_r_win), y = gov_r_win)) +\n    coord_flip() +\n  scale_y_continuous(name = \"Youngkin Outperformance to McAuliffe\", labels = scales::comma) +\n  scale_x_discrete(name = \"County\") +\n  labs(title = \"Race for Governor Comparison\") +\n  geom_col() \n\n\n\n\n\nHere I wanted to compare the two democrat candidates for governor and presidency and see if the governor got more or less percent vote than the president did.\n\nFirst I made a new column – d_gov_to_pres in order to show the difference between mcauliffe and biden by using mutate(pct_mcauliffe - biden_pct).\nThen I named the dataset d_gov_to_pres_joined_vacomparison in order to arrange the values in descending order using arrange(desc(new column I made)). I only needed the locality field and the difference in pctent votes so I selected only those two fields. Then I only wanted the top 10 so I headed it at 10.\nI made a datatable of my results by usinf the datatable function and putting in the dataset the information would come from – d_gov_to_pres_joined_vacomparison.\n\njoined_vacomparison <- joined_vacomparison %>% \nmutate(d_gov_to_pres = pct_mcauliffe - biden_pct)\n\nd_gov_to_pres_joined_vacomparison <- joined_vacomparison %>% \n  arrange(desc(d_gov_to_pres)) %>%\n  select(locality, d_gov_to_pres) %>% \n  head(10) \n\n\nDT::datatable(d_gov_to_pres_joined_vacomparison)\n\n\n\n\n\n\n\nLastly, I wanted a table that would show the top 5 counties that voted for Trump/ where Trump got the highest percentage of the vote.\n\nTo do this I made a new datatable named top_5_trump_counties from the original dataset. Then I selected only the fields I wanted which were the location – locality and the trump percent of votes – trump_pct. I then put them in descending order with arrange(desc(trump_pct)) and only took the top 5 by using head(5).\nTo make the table I just used the name of the dataset, used a pipe –> %>% and attached the datatable function.\n\ntop_5_trump_counties <- joined_vacomparison %>% \n  select(locality, trump_pct) %>%\n   arrange(desc(trump_pct)) %>% \n  head(5)\n\ntop_5_trump_counties %>% \n  DT::datatable(rownames = FALSE, filter = \"top\",\n                options = list(searching = FALSE, paging = FALSE, dom = \"tip\"))"
  },
  {
    "objectID": "01_virginia_election_project_datawrangling.html",
    "href": "01_virginia_election_project_datawrangling.html",
    "title": "Virginia Election Project",
    "section": "",
    "text": "Data available here: https://historical.elections.virginia.gov/elections/view/144567/\nA little column cleaning and we’ll load in the data file.\n\nprez_2020 <- read_csv(\"processed_data/va_2020_prez_cleaned.csv\")\n\nRows: 134 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): locality\nnum (3): biden, trump, total_votes_2021_prez\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLet’s see what we have\n\nhead(prez_2020) \n\n# A tibble: 6 × 4\n  locality         biden trump total_votes_2021_prez\n  <chr>            <dbl> <dbl>                 <dbl>\n1 Accomack County   7578  9172                 16962\n2 Albemarle County 42466 20804                 64657\n3 Alexandria City  66240 14544                 82508\n4 Alleghany County  2243  5859                  8203\n5 Amelia County     2411  5390                  7893\n6 Amherst County    5672 11041                 17005\n\n\nCalculating percentage of the vote\n\nprez_2020 %>% \n  mutate(\n    biden_pct = biden/total_votes_2021_prez\n  )\n\n# A tibble: 134 × 5\n   locality           biden trump total_votes_2021_prez biden_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962     0.447\n 2 Albemarle County   42466 20804                 64657     0.657\n 3 Alexandria City    66240 14544                 82508     0.803\n 4 Alleghany County    2243  5859                  8203     0.273\n 5 Amelia County       2411  5390                  7893     0.305\n 6 Amherst County      5672 11041                 17005     0.334\n 7 Appomattox County   2418  6702                  9268     0.261\n 8 Arlington County  105344 22318                130699     0.806\n 9 Augusta County     10840 30714                 42278     0.256\n10 Bath County          646  1834                  2501     0.258\n# … with 124 more rows\n\n\nNow let’s do some rounding and move that decimal point\n\nprez_2020 %>% \n  mutate(\n    biden_pct = janitor::round_half_up(biden / total_votes_2021_prez * 100, 1)\n  )\n\n# A tibble: 134 × 5\n   locality           biden trump total_votes_2021_prez biden_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962      44.7\n 2 Albemarle County   42466 20804                 64657      65.7\n 3 Alexandria City    66240 14544                 82508      80.3\n 4 Alleghany County    2243  5859                  8203      27.3\n 5 Amelia County       2411  5390                  7893      30.5\n 6 Amherst County      5672 11041                 17005      33.4\n 7 Appomattox County   2418  6702                  9268      26.1\n 8 Arlington County  105344 22318                130699      80.6\n 9 Augusta County     10840 30714                 42278      25.6\n10 Bath County          646  1834                  2501      25.8\n# … with 124 more rows\n\n\nNow trump too\n\nprez_2020 <- prez_2020 %>% \n  mutate(\n    biden_pct = janitor::round_half_up(biden / total_votes_2021_prez * 100, 2),\n    trump_pct = janitor::round_half_up(trump / total_votes_2021_prez * 100, 2)\n  )\n\nhead(prez_2020)\n\n# A tibble: 6 × 6\n  locality         biden trump total_votes_2021_prez biden_pct trump_pct\n  <chr>            <dbl> <dbl>                 <dbl>     <dbl>     <dbl>\n1 Accomack County   7578  9172                 16962      44.7      54.1\n2 Albemarle County 42466 20804                 64657      65.7      32.2\n3 Alexandria City  66240 14544                 82508      80.3      17.6\n4 Alleghany County  2243  5859                  8203      27.3      71.4\n5 Amelia County     2411  5390                  7893      30.6      68.3\n6 Amherst County    5672 11041                 17005      33.4      64.9"
  },
  {
    "objectID": "01_virginia_election_project_datawrangling.html#reshaping",
    "href": "01_virginia_election_project_datawrangling.html#reshaping",
    "title": "Virginia Election Project",
    "section": "Reshaping",
    "text": "Reshaping\nEnter pivot_wider().\nWe’ll get rid of everything we don’t need first.\n\ngov_2021 <- gov_2021 %>% \n  filter(ballot_name %in% c(\"Glenn A. Youngkin\", \"Terry R. McAuliffe\")) %>% \n  select(-locality_code,\n         -political_party)\n  \ngov_2021\n\n# A tibble: 266 × 4\n   locality_name    ballot_name        votes percentage\n   <chr>            <chr>              <int> <chr>     \n 1 ACCOMACK COUNTY  Glenn A. Youngkin   7878 61.08%    \n 2 ACCOMACK COUNTY  Terry R. McAuliffe  4948 38.37%    \n 3 ALBEMARLE COUNTY Glenn A. Youngkin  19141 37.21%    \n 4 ALBEMARLE COUNTY Terry R. McAuliffe 31919 62.05%    \n 5 ALEXANDRIA CITY  Glenn A. Youngkin  14013 24.02%    \n 6 ALEXANDRIA CITY  Terry R. McAuliffe 43866 75.20%    \n 7 ALLEGHANY COUNTY Glenn A. Youngkin   4530 74.52%    \n 8 ALLEGHANY COUNTY Terry R. McAuliffe  1518 24.97%    \n 9 AMELIA COUNTY    Glenn A. Youngkin   4720 74.19%    \n10 AMELIA COUNTY    Terry R. McAuliffe  1617 25.42%    \n# … with 256 more rows\n\n\nNow we’ll do the spreading out to reshape.\n\ngov_2021_wide <- gov_2021 %>% \n  pivot_wider(names_from = ballot_name, values_from = c(votes, percentage))\n\ngov_2021_wide\n\n# A tibble: 133 × 5\n   locality_name     `votes_Glenn A. Youngkin` votes_Terry R. …¹ perce…² perce…³\n   <chr>                                 <int>             <int> <chr>   <chr>  \n 1 ACCOMACK COUNTY                        7878              4948 61.08%  38.37% \n 2 ALBEMARLE COUNTY                      19141             31919 37.21%  62.05% \n 3 ALEXANDRIA CITY                       14013             43866 24.02%  75.20% \n 4 ALLEGHANY COUNTY                       4530              1518 74.52%  24.97% \n 5 AMELIA COUNTY                          4720              1617 74.19%  25.42% \n 6 AMHERST COUNTY                         9731              3897 71.00%  28.43% \n 7 APPOMATTOX COUNTY                      5971              1438 80.26%  19.33% \n 8 ARLINGTON COUNTY                      21548             73013 22.63%  76.67% \n 9 AUGUSTA COUNTY                        26196              7231 77.93%  21.51% \n10 BATH COUNTY                            1539               396 79.04%  20.34% \n# … with 123 more rows, and abbreviated variable names\n#   ¹​`votes_Terry R. McAuliffe`, ²​`percentage_Glenn A. Youngkin`,\n#   ³​`percentage_Terry R. McAuliffe`\n\n\nNice.\nThis is giving us some pretty long column names. we can change them after the fact using rename(). But first let’s clean the names to make it easier.\n\ngov_2021_wide <- gov_2021_wide %>% \n  clean_names()\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    votes_glenn_a_youngkin votes_terry_r_mc_aul…¹ perce…² perce…³\n  <chr>                             <int>                  <int> <chr>   <chr>  \n1 ACCOMACK COUNTY                    7878                   4948 61.08%  38.37% \n2 ALBEMARLE COUNTY                  19141                  31919 37.21%  62.05% \n3 ALEXANDRIA CITY                   14013                  43866 24.02%  75.20% \n4 ALLEGHANY COUNTY                   4530                   1518 74.52%  24.97% \n5 AMELIA COUNTY                      4720                   1617 74.19%  25.42% \n6 AMHERST COUNTY                     9731                   3897 71.00%  28.43% \n# … with abbreviated variable names ¹​votes_terry_r_mc_auliffe,\n#   ²​percentage_glenn_a_youngkin, ³​percentage_terry_r_mc_auliffe\n\n\nNow let’s rename, and we’ll use similar names to what we had earlier in our 2021 results.\n\ngov_2021_wide <- gov_2021_wide %>% \n  rename(\n    youngkin = votes_glenn_a_youngkin,\n    mcauliffe = votes_terry_r_mc_auliffe,\n    pct_youngkin = percentage_glenn_a_youngkin,\n    pct_mcauliffe = percentage_terry_r_mc_auliffe\n  )\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>               <int>     <int> <chr>        <chr>        \n1 ACCOMACK COUNTY      7878      4948 61.08%       38.37%       \n2 ALBEMARLE COUNTY    19141     31919 37.21%       62.05%       \n3 ALEXANDRIA CITY     14013     43866 24.02%       75.20%       \n4 ALLEGHANY COUNTY     4530      1518 74.52%       24.97%       \n5 AMELIA COUNTY        4720      1617 74.19%       25.42%       \n6 AMHERST COUNTY       9731      3897 71.00%       28.43%       \n\n\nBingo.\nThere’s still one potential issue here. Can you see it?\nThe percentage columns are actually text values, not numbers. And they have that % sign in the text too. Let’s fix that using a handy function from the readr package, parse_number().\n\ngov_2021_wide <- gov_2021_wide %>% \n  mutate(\n    pct_youngkin = readr::parse_number(pct_youngkin),\n    pct_mcauliffe = readr::parse_number(pct_mcauliffe)\n  )\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>               <int>     <int>        <dbl>         <dbl>\n1 ACCOMACK COUNTY      7878      4948         61.1          38.4\n2 ALBEMARLE COUNTY    19141     31919         37.2          62.0\n3 ALEXANDRIA CITY     14013     43866         24.0          75.2\n4 ALLEGHANY COUNTY     4530      1518         74.5          25.0\n5 AMELIA COUNTY        4720      1617         74.2          25.4\n6 AMHERST COUNTY       9731      3897         71            28.4\n\n\nPerfect. Problem solved."
  },
  {
    "objectID": "01_virginia_election_project_datawrangling.html#comparing-gov-vs.-prez-results",
    "href": "01_virginia_election_project_datawrangling.html#comparing-gov-vs.-prez-results",
    "title": "Virginia Election Project",
    "section": "Comparing gov vs. prez results",
    "text": "Comparing gov vs. prez results\nNow that things are join, let’s actually go ahead and start making columns to compare the two elections and how the candidates did this time compared with last time.\nWhere should we go from here….?"
  }
]